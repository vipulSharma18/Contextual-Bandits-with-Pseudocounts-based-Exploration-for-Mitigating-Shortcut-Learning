## SLURM PROLOG ###############################################################
##    Job ID : 1988335
##  Job Name : 6_5
##  Nodelist : gpu2001
##      CPUs : 1
##  Mem/Node : 10240 MB
## Directory : /oscar/scratch/vsharm44/rl_project/Exploration-For-Shortcut-Learning/contrastive_learning
##   Job Started : Fri May 10 11:40:13 PM EDT 2024
###############################################################################
Running for input 0.6_5
==========================================================================
Running experiment for setting 0.6_1
==========================================================================
Running for seed 1 of experiment 0.6_1
wandb: Currently logged in as: vipul. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /oscar/scratch/vsharm44/rl_project/Exploration-For-Shortcut-Learning/contrastive_learning/wandb/run-20240510_234019-3tk5fqlw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-eon-295
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vipul/RL_Project_CSCI2951F
wandb: üöÄ View run at https://wandb.ai/vipul/RL_Project_CSCI2951F/runs/3tk5fqlw
/users/vsharm44/.conda/envs/dl_project/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Epoch 0, Batch 0, train loss:7.749749183654785, Elapsed time for epoch : 0.017138397693634032
Epoch 0, Batch 10, train loss:2.8786063194274902, Elapsed time for epoch : 0.1337495764096578
Epoch 0, Batch 20, train loss:2.7323262691497803, Elapsed time for epoch : 0.24989571968714397
Epoch 0, Batch 30, train loss:2.5986077785491943, Elapsed time for epoch : 0.36644492149353025
Epoch 0, Batch 40, train loss:2.152283191680908, Elapsed time for epoch : 0.4830372929573059
Epoch 0, Batch 50, train loss:2.00974702835083, Elapsed time for epoch : 0.5997420032819112
slurmstepd: error: *** JOB 1988335 ON gpu2001 CANCELLED AT 2024-05-10T23:41:00 ***
